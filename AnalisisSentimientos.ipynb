{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gmRDAqKaFn8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a07ac8-a11e-4092-8b48-0605a366aef3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[381  49]\n",
            " [ 59 414]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88       430\n",
            "           1       0.89      0.88      0.88       473\n",
            "\n",
            "    accuracy                           0.88       903\n",
            "   macro avg       0.88      0.88      0.88       903\n",
            "weighted avg       0.88      0.88      0.88       903\n",
            "\n",
            "0.8803986710963455\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Jorge Manzano Anchelergues y Jaime Usero Aranda\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Sacamos los datos del csv\n",
        "comentarios = pd.read_csv(\"sentimientos.csv\")\n",
        "\n",
        "# Filtrar los comentarios negativos (sentimiento == 0)\n",
        "negativo = comentarios[comentarios['sentimiento'] == 0]\n",
        "\n",
        "# Filtrar los comentarios positivos (sentimiento == 1)\n",
        "positivo = comentarios[comentarios['sentimiento'] == 1]\n",
        "\n",
        "# Sacar el tamaño minimo de los dataframes\n",
        "min_size = min(len(positivo), len(negativo))\n",
        "\n",
        "# Recortar ambos DataFrames al tamaño mínimo\n",
        "positivo = positivo.sample(n=len(negativo), random_state=42)\n",
        "negativo = negativo.sample(n=len(negativo), random_state=42)\n",
        "\n",
        "# Limpiar los datos\n",
        "comentariosFiltrados = np.concatenate((positivo['comentario'].values, negativo['comentario'].values))\n",
        "sentimientos = np.concatenate((positivo['sentimiento'].values, negativo['sentimiento'].values))\n",
        "\n",
        "# Crear el vectorizador TF-IDF con parámetros adicionales\n",
        "try:\n",
        "  stopwords_spanish = stopwords.words('spanish')\n",
        "except:\n",
        "  nltk.download('stopwords')\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=2500,             # Limitar a las 2500 palabras más importantes\n",
        "    min_df=7,                      # Filtrar palabras que aparecen en menos de 7 documentos\n",
        "    max_df=0.8,                    # Filtrar palabras que aparecen en más del 80% de los documentos\n",
        "    stop_words=stopwords_spanish   # Eliminar las palabras comunes en español\n",
        ")\n",
        "\n",
        "# Ajustar y transformar los comentarios al modelo TF-IDF\n",
        "TfModel = tfidf_vectorizer.fit_transform(comentariosFiltrados).toarray()\n",
        "\n",
        "# Dividir los datos entre entrenamiento y testeo\n",
        "X_train, X_test, y_train, y_test = train_test_split(TfModel, sentimientos, test_size=0.2, random_state=0)\n",
        "\n",
        "# Entrenamos al modelo\n",
        "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
        "text_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "predictions = text_classifier.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,predictions))\n",
        "print(classification_report(y_test,predictions))\n",
        "print(accuracy_score(y_test, predictions))"
      ]
    }
  ]
}